{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "loose-singapore",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def load_fashion_mnist():\n",
    "    \"\"\"\n",
    "    Loads Fashion MNIST dataset.\n",
    "    \n",
    "    Adapted from: https://github.com/zalandoresearch/fashion-mnist/blob/master/utils/mnist_reader.py\n",
    "    \"\"\"\n",
    "    TRAIN_IMAGES = 'train-images-idx3-ubyte.gz'\n",
    "    TRAIN_LABELS = 'train-labels-idx1-ubyte.gz'    \n",
    "    TEST_IMAGES = 't10k-images-idx3-ubyte.gz'\n",
    "    TEST_LABELS = 't10k-labels-idx1-ubyte.gz'\n",
    "\n",
    "    with gzip.open(TRAIN_LABELS, 'rb') as tr_labels_file, gzip.open(TEST_LABELS, 'rb') as ts_labels_file:\n",
    "        train_labels = np.frombuffer(tr_labels_file.read(), dtype=np.uint8, offset=8)\n",
    "        test_labels = np.frombuffer(ts_labels_file.read(), dtype=np.uint8, offset=8)\n",
    "\n",
    "    with gzip.open(TRAIN_IMAGES, 'rb') as tr_images_file, gzip.open(TEST_IMAGES, 'rb') as ts_images_file:\n",
    "        train_images = np.frombuffer(tr_images_file.read(), dtype=np.uint8, offset=16).reshape(len(train_labels), 784)\n",
    "        test_images = np.frombuffer(ts_images_file.read(), dtype=np.uint8, offset=16).reshape(len(test_labels), 784)\n",
    "\n",
    "    return train_images, train_labels, test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "civilian-shift",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pretty_print(image_example):\n",
    "    \"\"\" Pretty prints a Fashion MNIST example.\n",
    "\n",
    "    Parameters:\n",
    "        image_example: a 1x784 numpy array corresponding to the features of\n",
    "                       a single image.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    print(np.array_str(image_example, precision=1, max_line_width=116))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "valuable-university",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def usage_example():\n",
    "    \"\"\" Example of how to load and parse Fashion MNIST data. \"\"\"\n",
    "    \n",
    "    train_images, train_labels, test_images, test_labels = load_fashion_mnist()\n",
    "\n",
    "    # train_images is a 60,000 x 784 numpy matrix. There are 60k\n",
    "    # rows in the matrix, each row corresponding to a single example.\n",
    "    # There are 784 columns, each corresponding to the value of a\n",
    "    # single pixel in the 28x28 image after it has been \"flattened\".\n",
    "    print(\"Dimensions of training set feature matrix:\", train_images.shape)\n",
    "\n",
    "    # The labels for each example are maintained separately in train_labels.\n",
    "    # This is a 60,000 x 1 numpy matrix, where each element is the label\n",
    "    # for the corresponding training example.\n",
    "    print(\"Dimensions of training set label matrix:\", train_labels.shape)\n",
    "\n",
    "    # Example of how to access a individual training example (in this case,\n",
    "    # we pick an example at a random index). We could use print to output the\n",
    "    # raw pixel values to the screen, but pretty_print formats the data in \n",
    "    # a nicer way: if you squint, you may be able to make out the contours of\n",
    "    # the fashion article in the matrix data.\n",
    "    EXAMPLE_INDEX = np.random.randint(60000)\n",
    "    print(\"Features of training example at index {}:\\n\".format(EXAMPLE_INDEX))\n",
    "    pretty_print(train_images[EXAMPLE_INDEX])\n",
    "\n",
    "    # And here's the label that goes with that training example\n",
    "    print(\"\\nLabel of training example at index {}:\".format(EXAMPLE_INDEX), train_labels[EXAMPLE_INDEX], '\\n')\n",
    "\n",
    "    # Finally, let's visualize the example we've picked as a 28x28 image\n",
    "    plt.figure()\n",
    "    plt.imshow(train_images[EXAMPLE_INDEX].reshape(28, 28))\n",
    "    plt.show()\n",
    "    \n",
    "    # The test_images/test_labels are organized in the same way, but only contain 10k\n",
    "    # examples. Don't touch this data until your model is frozen! Perform all\n",
    "    # cross-validation, model selection, hyperparameter tuning etc. on the 60k\n",
    "    # training set. Use the test set simply for reporting performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "international-lemon",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of training set feature matrix: (60000, 784)\n",
      "Dimensions of training set label matrix: (60000,)\n",
      "Features of training example at index 46757:\n",
      "\n",
      "[  0   0   0   0   0   0   0   0   0   0 106 211 215 122 141 188 203 126   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0 215 245 240 255 255 245 223 241  36   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0 186 240 227 229 232 227 218 212   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0 201 246 224 226 228 225 222 190   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0 186 248 229 231 231 228 229 184   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0 221 244 232 235 235 233 228 215   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   1   0 145 249 230 234 234 230 233 149   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   2   0  83 251 229 232 235 228 236  89   0   1   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   3   0  90 251 228 234 236 227 234  99   0   1   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   2   0  79 251 228 232 236 225 236 105   0   1   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   1   0 133 249 228 234 235 224 236 141   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0 211 247 230 232 236 224 232 220   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0 217 240 232 231 236 223 226 222  27   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0 233 237 233 231 235 220 228 232 102   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  53 247 235 234 230 235 220 231 230 177   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  90 253 235 236 232 235 221 234 227 219   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0 120 253 234 236 233 234 221 235 224 244   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0 146 250 235 235 232 234 220 235 223 224   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0 170 247 236 236 233 235 221 242 225 235   6   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0 196 247 236 237 233 237 223 244 225 255  21   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0 206 246 237 236 233 236 222 243 225 255  66   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0 217 247 237 237 233 236 223 244 227 255  94   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0 225 247 238 239 234 234 224 244 229 255 117   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0 238 244 239 238 234 234 224 245 224 255 124   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0 207 243 239 239 235 236 224 248 223 254 152   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0 219 236 234 232 228 227 217 236 226 250 162   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  19 248 238 249 255 255 254 255 255 243 254 214   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0 141 204 120 109 154 145 167 160 160 208 122   0   0   0   0   0   0   0   0]\n",
      "\n",
      "Label of training example at index 46757: 3 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "usage_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86c06bfd-2b65-4308-8536-78f85c534c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "train_images, train_labels, test_images, test_labels = load_fashion_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9275c0bb-90e0-4863-a352-af06d65f2441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fed345f-d1da-4c5a-8fb8-bf91cac58d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#These are completely balanced\n",
    "r = [0,1,2,3,4,5,6,7,8,9,10]\n",
    "np.histogram(train_labels, bins=r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1166b467-4342-47e7-a470-329c35637472",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "from scipy import stats\n",
    "def compute_distances(train_X, test_example):\n",
    "    \"\"\"\n",
    "    Returns a vector of the distances between the given test_example\n",
    "    and every training example in the matrix train_X.\n",
    "    \n",
    "    Parameters:\n",
    "        train_X - an nx3 matrix, containing n training examples\n",
    "        test_examples - a 1x3 vector containing a test example to classify\n",
    "        \n",
    "    Returns:\n",
    "        An nx1 matrix containing the distances from test_example to all the\n",
    "        examples in train_X.\n",
    "    \"\"\"\n",
    "    \n",
    "    return LA.norm(train_X - test_example, ord=1, axis=1)\n",
    "\n",
    "def predict_one(distances, y_train, k):\n",
    "    \"\"\"\n",
    "    Given a vector of distances between a test example and all the training examples,\n",
    "    makes a prediction using a majority vote of k nearest neighbors.\n",
    "    \n",
    "    Parameters:\n",
    "        distances - an nx1 matrix containing the distances from a test example to\n",
    "                    all training examples.\n",
    "        train_y - an nx1 matrix containing the true labels\n",
    "        k - the number of neighbors participating in the prediction\n",
    "        \n",
    "    Returns:\n",
    "        A classification for the test example in question (i.e., either a 0 or a 1).\n",
    "    \"\"\"\n",
    "    result = np.argpartition(distances,k)[:k]\n",
    "    classification = y_train[result]\n",
    "    return stats.mode(classification, axis=None)[0][0]\n",
    "\n",
    "def predict_all(X_train, y_train, X_test, k):\n",
    "    \"\"\"\n",
    "    Makes a k-NN prediction for every example in X_test, using (X_train, y_train).\n",
    "    \n",
    "    Parameters:\n",
    "        X_train - matrix of training data\n",
    "        y_train - vector of training labels\n",
    "        X_test - matrix of test data to be classified\n",
    "        k - the number of nearest neighbors participating in the classification.\n",
    "        \n",
    "    Returns:\n",
    "        An nx1 matrix of predictions for every test case.\n",
    "    \"\"\"\n",
    "    y_preds = []\n",
    "    for ex in X_test:\n",
    "        distances = compute_distances(X_train, ex)\n",
    "        p = predict_one(distances, y_train, k)\n",
    "        y_preds.append(p)\n",
    "    return y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14860462-e4a0-4519-bd66-f113919b4b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "tI = train_images[:1000]\n",
    "tL = train_labels[:1000]\n",
    "teI = test_images[:1000]\n",
    "teL = test_labels[:1000]\n",
    "from sklearn.metrics import confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbd84512-bd2d-4921-a5d9-a0dee122e1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_binary(image):\n",
    "    binary = np.zeros(image.shape)\n",
    "    for i in range(0,image.shape[0]):\n",
    "        if image[i] > 128 :\n",
    "            binary[i] = 1\n",
    "    return binary\n",
    "\n",
    "def all_to_binary(images):\n",
    "    binary = []\n",
    "    for image in images:\n",
    "        binary.append(convert_to_binary(image))\n",
    "    return np.array(binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a3ec0ed-209c-4407-bef1-2762825d347c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#binary training\n",
    "tIb = all_to_binary(train_images)\n",
    "teIb = all_to_binary(test_images)\n",
    "tIb5 = tIb[:1000]\n",
    "teIb5 = teIb[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bae169-f34d-4eb0-955c-22a073240ddc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Non binary with our KNN Implementation\n",
    "preds = predict_all(tI, tL, teI, 5)\n",
    "print(\"Non-Binary Values\")\n",
    "print(confusion_matrix(teL, preds))\n",
    "print(f1_score(teL, preds, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c2ed599-f59d-4377-ae57-aa90e32ee62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Values\n",
      "[[77  0  4  1  0  0 13  7  5  0]\n",
      " [ 3 94  0  4  0  0  2  1  1  0]\n",
      " [ 9  0 64  0 18  0 13  5  2  0]\n",
      " [ 8  4  0 68  1  0  6  5  1  0]\n",
      " [ 5  2 17  7 77  0  7  0  0  0]\n",
      " [ 0  0  0  0  0 51  1 26  0  9]\n",
      " [26  0 15  2 10  0 42  1  1  0]\n",
      " [ 0  0  0  0  0  4  0 82  0  9]\n",
      " [ 0  1  1  1  2  8  0 11 71  0]\n",
      " [ 0  0  0  0  0  2  0  7  0 86]]\n",
      "0.712\n"
     ]
    }
   ],
   "source": [
    "#Binary values with our KNN Implementation\n",
    "predsb = predict_all(tIb5, tL, teIb5, 5)\n",
    "print(\"Binary Values\")\n",
    "print(confusion_matrix(teL, predsb))\n",
    "print(f1_score(teL, predsb, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08b7357f-b2ed-4e97-9415-ffc4505223db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.72      0.66       107\n",
      "           1       0.93      0.90      0.91       105\n",
      "           2       0.63      0.58      0.60       111\n",
      "           3       0.82      0.73      0.77        93\n",
      "           4       0.71      0.67      0.69       115\n",
      "           5       0.78      0.59      0.67        87\n",
      "           6       0.50      0.43      0.46        97\n",
      "           7       0.57      0.86      0.68        95\n",
      "           8       0.88      0.75      0.81        95\n",
      "           9       0.83      0.91      0.86        95\n",
      "\n",
      "    accuracy                           0.71      1000\n",
      "   macro avg       0.73      0.71      0.71      1000\n",
      "weighted avg       0.72      0.71      0.71      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(teL, predsb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7ed96f-ada9-43f6-bf37-4663792ee476",
   "metadata": {},
   "source": [
    "Change around the k value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56ef40c-9432-4ff2-a366-9e9bccea9ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for k in range(1,35,2):\n",
    "    preds = predict_all(tIb5, tL, teIb5, k)\n",
    "    scores.append(f1_score(teL, preds, average='micro'))\n",
    "\n",
    "plt.xlabel('K Values')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('FMNIST Binary')\n",
    "plt.plot(np.arange(1,35,2),scores, \"o-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd49b9e8-2008-4288-b19f-88edc8edfe63",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for k in range(1,35,2):\n",
    "    preds = predict_all(tI, tL, teI, k)\n",
    "    scores.append(f1_score(teL, preds, average='micro'))\n",
    "\n",
    "plt.xlabel('K Values')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('FMNIST Normal')\n",
    "plt.plot(np.arange(1,35,2),scores, \"o-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c172bb28-2dd4-4dd0-a75a-8bc417af3eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting figures \n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(20):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i].reshape(28, 28), cmap=plt.cm.binary)\n",
    "    plt.xlabel(train_labels[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b9fdcc2-5a38-429a-8446-903522c4b0ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8554"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#implementation of the scikit k-nearest neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "neigh.fit(train_images, train_labels)\n",
    "#params = neigh.get_params(deep=True)\n",
    "\n",
    "preds1 = neigh.predict(test_images)\n",
    "\n",
    "accuracy_score(test_labels, preds1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc40195c-1033-40b0-8f26-cecd75c5a13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for k in range(1,35,2):\n",
    "    neigh = KNeighborsClassifier(n_neighbors=k)\n",
    "    neigh.fit(tIb, train_labels)\n",
    "    preds = neigh.predict(teIb)\n",
    "    scores.append(accuracy_score(test_labels, preds))\n",
    "\n",
    "plt.xlabel('K Values')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('FMNIST SciKit')\n",
    "plt.plot(np.arange(1,35,2),scores, \"o-\")\n",
    "print(\"Binary accuracy of models:\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75a8e2f-f14d-4b09-8c4d-cac2d89a81ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresNonB = []\n",
    "for k in range(1,35,2):\n",
    "    neigh = KNeighborsClassifier(n_neighbors=k)\n",
    "    neigh.fit(train_images, train_labels)\n",
    "    preds = neigh.predict(test_images)\n",
    "    scoresNonB.append(accuracy_score(test_labels, preds))\n",
    "\n",
    "plt.xlabel('K Values')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('FMNIST SciKit')\n",
    "plt.plot(np.arange(1,35,2),scoresNonB, \"o-\")\n",
    "print(\"Non-Binary accuracy of models:\", scoresNonB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78754a40-8e11-4090-b674-99d518e74d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparing actual positives to false positives, with its accuracy score\n",
    "print(confusion_matrix(test_labels, preds1))\n",
    "print(accuracy_score(test_labels, preds1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6325b1-11b3-442c-933c-0a730b8c2a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#break down of the accuracy of each label for knn \n",
    "print(classification_report(test_labels, preds1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c96a613-14ea-464a-98b1-4dd9a95e0571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/pub/eb/apps/all/DavidsonJupyter/2021-common-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#implementation of the logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logReg = LogisticRegression(random_state=0)\n",
    "logReg.fit(train_images, train_labels)\n",
    "pr = logReg.predict(test_images)\n",
    "print(accuracy_score(test_labels, pr))\n",
    "#Actually pretty good accuracy, comparable to the knn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f83a777-221e-4617-ac92-f399cda187fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/pub/eb/apps/all/DavidsonJupyter/2021-common-GCCcore-10.2.0/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logReg = LogisticRegression(random_state=0)\n",
    "logReg.fit(tIb, train_labels)\n",
    "pr = logReg.predict(teIb)\n",
    "print(accuracy_score(test_labels, pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f19881-d955-462b-9fdf-c047d421a307",
   "metadata": {},
   "outputs": [],
   "source": [
    "#break down of the accuracy of each label for logReg\n",
    "print(classification_report(test_labels, pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fa7c80-7428-4837-bf4b-c1a0cbf40932",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(test_labels, pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4eb06f-92d8-449f-bbab-b1f083d1e259",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
